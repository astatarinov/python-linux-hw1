Домашнее задание 1
Напишите web crawler, обходящий некоторый сайт и скачивающий его
страницы.
Результат выполнения задания - питон скрипт, который можно
запустить, передав 2 аргумента командной строки - начальный url и
глубину обхода. Скрипт должен скачивать страницы по url, сохранять их
содержимое на диск, а также искать в них ссылки и рекурсивно
выкачивать их. В результате выполнения должны появиться файл urls.txt
и папка data. В файле urls.txt должны быть записаны пары id-url по
одной на строку, разделенные пробелом, например:
1 https://yandex.ru
2 https://yandex.ru/news
В папке data должны лежать файлы 1.html, 2.html и так далее, внутри у
них должен быть полный html страницы, находящейся по url с
соответствующим id.

Оценка:
• [4 балла] Работоспособность программы - то что ее можно запустить и она
выполняет задание. Неработоспособные решения не могут получить выше 3
баллов.
• [4 балла] Корректность и адекватность программы - то, что выполнены все пункты
условия, а так же корректная обработка ошибок, правильный выбор структур
данных, то что каждая страница запрашивается только один раз и так далее
• [2 балла] Стиль кода - соблюдение styleguide:
• https://www.python.org/dev/peps/pep-0008/
• https://github.com/google/styleguide/blob/gh-pages/pyguide.md
Hard